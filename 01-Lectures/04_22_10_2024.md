# 4. Week - 22 October 2024 Tuesday

## Ödev

* Ödev Stockhastice Gradient Descent (SGD) ve Quasi Newton ile alakalı olacak
* 6 hafta dersi işledikten sonra verilecek.

## Approximationg Derivatives

* Bir fornksiyonun türevini almak çok zor veya maliyetli olabilir.
* Bu durumlarda türevi almak yerine türevine yakınsayan farklı bir yöntemle ilerlemek gerekiyor.
* forward: f(x + delta)
* backward: f(x - delta)
* central: f(x + delta/2) - f(x - delta/2)

Central olanın türeve göre yaptığı hata çok azdır. Forward veya backward yerine central kullanabiliriz.

* Quadratic -> 2. dereceden fonksiyon/denklem demek
* Optimizasyonda en sevdiğimiz fonksiyon tipi positive definite olandır. Convex bir fonksiyon olduğu için hemen çözebiliriz. Quadratic fonksiyonda diyebiliriz.
* Negative definite ise concavdır. ters çevirip çözebiliriz.
* Indefinite ise çözmemiz diğerleri kadar kolay değil. Local minimumda takılıp kalabiliriz.

# Types of Regression Models

re_mfa.pptx ile devam ediyoruz.

* Linear kelimesi bulmaya çalıştığımız beta nın linear olduğunu ifade ediyor.
* First order x li deyimin üssünün 1 olduğunu ifade ediyor
* Second order x li deyimin üssünün 2 oldu
* L1 Regularization -> Linear First Order Regularization
* L2 Regularization -> Linear Second Order Regularization
* Regülarizasyonda Beta ları bulmaya çalışıyoruz.

Y = Beta0 + Beta1 * x

* Elimizde X lere (inputlar) karşılık Y ler (output) var.
* Betaları tahmin etmeye çalışıyoruz. Betaların gerçek değerini bilmiyoruz.
* Tahmin ettiğimiz betalar ile oluşan Ytahmin değerini gerçek Y ile karşılaştırarak tahminimizin doğruluğuna karar veriyoruz.